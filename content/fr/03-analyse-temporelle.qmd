---
title: "Analyse temporelle : Le film amÃ©ricain"
execute:
  cache: false
---

{{< include _setup.qmd >}}
{{< include _footnotes.qmd >}}

```{python}
#| label: estimation-ardl-v1
#| output: false

if DATA_LOADED and not df_usa.empty:
    m_ar = smf.ols('log_co2 ~ lag_log_co2', data=df_usa).fit()
    m_ardl_lin = smf.ols('log_co2 ~ lag_log_co2 + log_gdp_c', data=df_usa).fit()
    m_ardl_quad = smf.ols('log_co2 ~ lag_log_co2 + log_gdp_c + I(log_gdp_c**2)', data=df_usa).fit()
    m_ardl_cub = smf.ols('log_co2 ~ lag_log_co2 + log_gdp_c + I(log_gdp_c**2) + I(log_gdp_c**3)', data=df_usa).fit(cov_type='HAC', cov_kwds={'maxlags': 3})
    
    RHO = m_ardl_cub.params.get('lag_log_co2', 0)
    BETA3_USA = m_ardl_cub.params.get('I(log_gdp_c ** 3)', 0)
    PVAL3_USA = m_ardl_cub.pvalues.get('I(log_gdp_c ** 3)', 1)
    
    HALFLIFE = np.log(0.5) / np.log(RHO) if 0 < RHO < 1 else np.nan
```

## Pourquoi les Ã‰tats-Unis ?

- Premier Ã©metteur cumulÃ© historique (~25% du CO$_2$ mondial depuis 1850)
- Ã‰conomie post-industrielle mature (76 000 $/hab)
- DonnÃ©es d'Ã©missions territoriales complÃ¨tes (`{python} ANNEE_DEBUT_DATA`-`{python} ANNEE_FIN`)

## Tests de stationnaritÃ© (ADF[^adf])

```{python}
#| echo: false

if DATA_LOADED and not df_usa.empty:
    from statsmodels.tsa.stattools import adfuller
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. TESTS ADF AVEC DIAGNOSTIC COMPLET
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Tests en niveaux
    adf_co2 = adfuller(df_usa['log_co2'], autolag='AIC', regression='ct')  # avec constante + tendance
    adf_gdp = adfuller(df_usa['log_gdp'], autolag='AIC', regression='ct')
    
    # Tests en diffÃ©rences premiÃ¨res
    adf_co2_diff = adfuller(df_usa['log_co2'].diff().dropna(), autolag='AIC', regression='c')  # constante seule
    adf_gdp_diff = adfuller(df_usa['log_gdp'].diff().dropna(), autolag='AIC', regression='c')
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. FONCTION D'INTERPRÃ‰TATION AUTOMATIQUE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def interprete_adf(pval_niveaux, pval_diff, seuil=0.05):
        """
        Retourne I(0), I(1), ou 'Ambigu' selon les p-values
        
        Logique :
        - Si p(niveaux) < seuil : REJETTE H0 â†’ stationnaire â†’ I(0)
        - Si p(niveaux) >= seuil ET p(diff) < seuil : non-stat en niveaux, stat en diff â†’ I(1)
        - Sinon : Ambigu (faible puissance du test)
        """
        if pval_niveaux < seuil:
            return "I(0)", "âœ… Stationnaire en niveaux"
        elif pval_diff < seuil:
            return "I(1)", "âœ… Non-stationnaire en niveaux, stationnaire en diffÃ©rence"
        else:
            return "Ambigu", "âš ï¸ Tests non conclusifs (possiblement I(2) ou break structurel)"
    
    # Application
    concl_co2, msg_co2 = interprete_adf(adf_co2[1], adf_co2_diff[1])
    concl_gdp, msg_gdp = interprete_adf(adf_gdp[1], adf_gdp_diff[1])
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. AFFICHAGE DU TABLEAU
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    display(Markdown(f"""
**Tests de stationnaritÃ© (ADF avec constante + tendance)**

| Variable | ADF (niveaux) | p-value | ADF (diff.) | p-value | **Conclusion** |
|----------|---------------|---------|-------------|---------|----------------|
| $\\ln(\\text{{CO}}_2)$ | {adf_co2[0]:.2f} | **{adf_co2[1]:.3f}** | {adf_co2_diff[0]:.2f} | {adf_co2_diff[1]:.3f} | **{concl_co2}** |
| $\\ln(\\text{{PIB}})$ | {adf_gdp[0]:.2f} | **{adf_gdp[1]:.3f}** | {adf_gdp_diff[0]:.2f} | {adf_gdp_diff[1]:.3f} | **{concl_gdp}** |

*Rappel : Hâ‚€ = "prÃ©sence d'une racine unitaire (non-stationnaire)". Si p < 0.05, on rejette Hâ‚€ â†’ sÃ©rie stationnaire (I(0)).*
"""))
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. INTERPRÃ‰TATION CONDITIONNELLE ET AVERTISSEMENT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    if concl_co2 == concl_gdp == "I(1)":
        # CAS IDÃ‰AL : Les deux sÃ©ries sont I(1)
        display(Markdown("""
**âœ… InterprÃ©tation** : Les deux sÃ©ries sont **I(1)** (non-stationnaires en niveaux, stationnaires en diffÃ©rence premiÃ¨re).

**Implication mÃ©thodologique** : Le modÃ¨le **ARDL** est adaptÃ©. Si les sÃ©ries sont cointÃ©grÃ©es, l'ARDL capturera la relation de long terme. Sinon, il dÃ©crira correctement la dynamique de court terme.
"""))
    
    elif concl_co2 == "I(0)" and concl_gdp == "I(0)":
        # CAS 2 : Les deux I(0)
        display(Markdown("""
**âœ… InterprÃ©tation** : Les deux sÃ©ries sont **I(0)** (stationnaires en niveaux).

**Implication mÃ©thodologique** : Le modÃ¨le ARDL reste valide. On peut aussi estimer un modÃ¨le statique (OLS simple) sans retards, mais l'ARDL capturera mieux les dynamiques d'ajustement.
"""))
    
    elif (concl_co2 == "I(1)" and concl_gdp == "I(0)") or (concl_co2 == "I(0)" and concl_gdp == "I(1)"):
        # CAS PROBLÃ‰MATIQUE : AsymÃ©trie I(0)/I(1)
        display(Markdown(f"""
**âš ï¸ DIAGNOSTIC : AsymÃ©trie d'intÃ©gration dÃ©tectÃ©e**

- $\\ln(\\text{{CO}}_2)$ : **{concl_co2}** ({msg_co2})
- $\\ln(\\text{{PIB}})$ : **{concl_gdp}** ({msg_gdp})

**ProblÃ¨me thÃ©orique** : RÃ©gresser une variable I(1) sur une variable I(0) (ou inversement) peut conduire Ã  des rÃ©sultats biaisÃ©s si les sÃ©ries ne sont pas cointÃ©grÃ©es.

**Solution adoptÃ©e** : Le modÃ¨le **ARDL reste valide** dans ce cas (Pesaran et al., 2001) :
- L'ARDL accepte un mÃ©lange de rÃ©gresseurs I(0) et I(1)
- Condition : aucune variable ne doit Ãªtre I(2) (ce qui est vÃ©rifiÃ© ici)
- Test de robustesse recommandÃ© : **Test de Bounds** pour la cointÃ©gration (non effectuÃ© dans ce rapport)

**InterprÃ©tation prudente** : Les Ã©lasticitÃ©s de long terme doivent Ãªtre interprÃ©tÃ©es avec rÃ©serve. L'inertie temporelle (coefficient $\\rho$) reste fiable.
"""))
    
    else:
        # CAS 4 : Au moins un test ambigu
        display(Markdown(f"""
**âš ï¸ DIAGNOSTIC : Tests ADF non conclusifs**

- $\\ln(\\text{{CO}}_2)$ : {concl_co2}
- $\\ln(\\text{{PIB}})$ : {concl_gdp}

**Causes possibles** :
1. **Faible puissance du test** (Ã©chantillon T=30 trop petit)
2. **Break structurel** (ex: crise 2008, COVID-2020) non pris en compte
3. **SÃ©rie I(2)** (peu probable pour PIB et COâ‚‚)

**Solution adoptÃ©e** : Nous procÃ©dons avec le modÃ¨le **ARDL**, mais reconnaissons que les tests de stationnaritÃ© sont peu conclusifs sur petit Ã©chantillon.

**Test de robustesse alternatif** : KPSS (Hâ‚€ = stationnaritÃ©) ou Phillips-Perron pourraient Ãªtre utilisÃ©s en complÃ©ment.
"""))
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. TEST SUPPLÃ‰MENTAIRE : ADF SANS TENDANCE (robustesse)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    if concl_gdp == "I(0)" and adf_gdp[1] < 0.10:  # Si rÃ©sultat borderline
        adf_gdp_no_trend = adfuller(df_usa['log_gdp'], autolag='AIC', regression='c')  # constante seule
        
        display(Markdown(f"""
---

**ğŸ” Test de robustesse (ln(PIB) avec spÃ©cification alternative)**

La p-value proche du seuil (p={adf_gdp[1]:.3f}) peut Ãªtre sensible Ã  la spÃ©cification du test (avec/sans tendance).

| SpÃ©cification | ADF | p-value | Conclusion |
|---------------|-----|---------|------------|
| Constante + Tendance | {adf_gdp[0]:.2f} | {adf_gdp[1]:.3f} | {concl_gdp} |
| Constante seule | {adf_gdp_no_trend[0]:.2f} | {adf_gdp_no_trend[1]:.3f} | {"I(0)" if adf_gdp_no_trend[1] < 0.05 else "I(1)"} |

**InterprÃ©tation** : {
    "Les deux spÃ©cifications convergent â†’ rÃ©sultat robuste." 
    if (adf_gdp[1] < 0.05) == (adf_gdp_no_trend[1] < 0.05)
    else "**Divergence dÃ©tectÃ©e** â†’ ln(PIB) est probablement **trend-stationary** (I(0) autour d'une tendance dÃ©terministe, pas I(1)). Le modÃ¨le ARDL reste valide."
}
"""))
```

**Conclusion** : Les sÃ©ries sont $I(1) \rightarrow$ modÃ¨le **ARDL** adaptÃ©.

## Estimation des modÃ¨les candidats {#sec-estimation-usa}

Nous estimons **quatre spÃ©cifications ARDL**[^ardl] pour capturer la relation dynamique entre le $\text{PIB}$ et le $\text{CO}_2$ :

1. **AR(1)** : ModÃ¨le autorÃ©gressif pur (sans $\text{PIB}$) â€” benchmark minimal
2. **ARDL linÃ©aire** : Ajoute $\ln(\text{PIB})$ comme rÃ©gressor
3. **ARDL quadratique** : Ajoute $[\ln(\text{PIB})]^2$
4. **ARDL cubique** : Ajoute $[\ln(\text{PIB})]^3$ (test du rebond)

```{python}
#| label: estimation-ardl-v2
#| output: false

if DATA_LOADED and not df_usa.empty:
    # Estimation avec erreurs-types Newey-West (3 lags)
    m_ar = smf.ols('log_co2 ~ lag_log_co2', data=df_usa).fit(
        cov_type='HAC', cov_kwds={'maxlags': 3})
    
    m_ardl_lin = smf.ols('log_co2 ~ lag_log_co2 + log_gdp_c', data=df_usa).fit(
        cov_type='HAC', cov_kwds={'maxlags': 3})
    
    m_ardl_quad = smf.ols('log_co2 ~ lag_log_co2 + log_gdp_c + I(log_gdp_c**2)', 
        data=df_usa).fit(cov_type='HAC', cov_kwds={'maxlags': 3})
    
    m_ardl_cub = smf.ols('log_co2 ~ lag_log_co2 + log_gdp_c + I(log_gdp_c**2) + I(log_gdp_c**3)', 
        data=df_usa).fit(cov_type='HAC', cov_kwds={'maxlags': 3})
```

```{python}
#| label: tbl-ardl
#| tbl-cap: "ModÃ¨les ARDL â€” Ã‰tats-Unis (1990-2020)"
#| echo: false

from IPython.display import display, Markdown
import statsmodels.formula.api as smf
import numpy as np

# VÃ©rification de sÃ©curitÃ©
if 'DATA_LOADED' in locals() and DATA_LOADED and not df_usa.empty:
    
    # 1. Fonction de formatage
    def fmt_ardl(model, var):
        """Formate coefficient (erreur-type) avec Ã©toiles"""
        # Statsmodels peut Ãªtre sensible aux espaces dans les noms de variables I()
        # On vÃ©rifie si la variable existe exactement
        if var not in model.params.index:
            return "â€”"
        c = model.params[var]
        s = model.bse[var]
        p = model.pvalues[var]
        stars = '***' if p < 0.01 else '**' if p < 0.05 else '*' if p < 0.1 else ''
        return f"{c:.4f}{stars} ({s:.4f})"
    
    # 2. Estimation des modÃ¨les (HAC pour robustesse)
    kwds = {'maxlags': 3}
    m_ar = smf.ols('log_co2 ~ lag_log_co2', data=df_usa).fit(cov_type='HAC', cov_kwds=kwds)
    m_ardl_lin = smf.ols('log_co2 ~ lag_log_co2 + log_gdp_c', data=df_usa).fit(cov_type='HAC', cov_kwds=kwds)
    m_ardl_quad = smf.ols('log_co2 ~ lag_log_co2 + log_gdp_c + I(log_gdp_c**2)', data=df_usa).fit(cov_type='HAC', cov_kwds=kwds)
    m_ardl_cub = smf.ols('log_co2 ~ lag_log_co2 + log_gdp_c + I(log_gdp_c**2) + I(log_gdp_c**3)', data=df_usa).fit(cov_type='HAC', cov_kwds=kwds)
    
    # 3. Construction du tableau
    # Note: Assurez-vous que les noms ici correspondent EXACTEMENT aux params du modÃ¨le (print(m_ardl_cub.params.index) pour vÃ©rifier)
    rows = [
        ('$\\ln(\\text{CO}_2)_{t-1}$', 'lag_log_co2'),
        ('$\\ln(\\text{PIB})_t$', 'log_gdp_c'),
        ('$[\\ln(\\text{PIB})]^2$', 'I(log_gdp_c ** 2)'), 
        ('$[\\ln(\\text{PIB})]^3$', 'I(log_gdp_c ** 3)'),
    ]
    
    table = "| Variable | AR(1) | ARDL lin. | ARDL quad. | ARDL cub. |\n"
    table += "|----------|-------|-----------|------------|----------|\n"
    
    for label, var in rows:
        table += f"| {label} | {fmt_ardl(m_ar, var)} | {fmt_ardl(m_ardl_lin, var)} | "
        table += f"{fmt_ardl(m_ardl_quad, var)} | {fmt_ardl(m_ardl_cub, var)} |\n"
    
    table += f"| **RÂ²** | {m_ar.rsquared:.3f} | {m_ardl_lin.rsquared:.3f} | "
    table += f"{m_ardl_quad.rsquared:.3f} | {m_ardl_cub.rsquared:.3f} |\n"
    table += f"| **AIC** | {m_ar.aic:.1f} | {m_ardl_lin.aic:.1f} | "
    table += f"{m_ardl_quad.aic:.1f} | {m_ardl_cub.aic:.1f} |\n"
    
    display(Markdown(table))
    display(Markdown("*Erreurs-types Newey-West (3 lags). \\*p<0.1, \\*\\*p<0.05, \\*\\*\\*p<0.01*"))

    # 4. Calculs pour le texte d'observation
    # Trouver le meilleur modÃ¨le selon l'AIC
    models_aic = [m_ar.aic, m_ardl_lin.aic, m_ardl_quad.aic, m_ardl_cub.aic]
    model_names = ['AR', 'LinÃ©aire', 'Quadratique', 'Cubique']
    best_aic_model = model_names[np.argmin(models_aic)]
    
    # RÃ©cupÃ©ration p-value cubique (gestion d'erreur si la clÃ© diffÃ¨re lÃ©gÃ¨rement)
    try:
        p_val_cub = m_ardl_cub.pvalues['I(log_gdp_c ** 3)']
    except KeyError:
        # Fallback : essaie sans espaces si statsmodels a nettoyÃ© le nom
        p_val_cub = m_ardl_cub.pvalues.get('I(log_gdp_c**3)', 1.0)

    # 5. Affichage du texte d'observation dynamique
    display(Markdown(f"""
***

**Observation prÃ©liminaire** : 
- Le modÃ¨le cubique a le meilleur RÂ² ({m_ardl_cub.rsquared:.3f}), 
  mais Î²â‚ƒ est non significatif (p = {p_val_cub:.3f}).
- L'AIC favorise le modÃ¨le **{best_aic_model}**.

**â†’ Nous devons arbitrer entre significativitÃ© statistique et parcimonie. 
La validation hors-Ã©chantillon va trancher.**
    """))

else:
    print("DonnÃ©es non chargÃ©es.")
```

## Validation hors-Ã©chantillon {#sec-validation-usa}

### Protocole

**Pourquoi un simple train/test split (et pas expanding window) ?**

L'expanding window (Section 3.3.2.2) est thÃ©oriquement supÃ©rieur pour les sÃ©ries 
temporelles, mais avec seulement **30 observations**, une fenÃªtre expansive de 
10 itÃ©rations donnerait :

- 1Ã¨re itÃ©ration : 21 observations d'entraÃ®nement (1990-2010)
- DerniÃ¨re itÃ©ration : 30 observations (1990-2019)

â†’ Trop peu de donnÃ©es pour estimer robustement un modÃ¨le ARDL cubique (4 paramÃ¨tres).

**Compromis adoptÃ©** : Train/test split fixe (1990-2015 / 2016-2020) avec **5 observations test**, 
cohÃ©rent avec la rÃ¨gle empirique 80/20.

```{python}
#| label: validation-setup
#| output: false

train = df_usa[df_usa['year'] <= 2015].copy()
test = df_usa[df_usa['year'] > 2015].copy()

# RÃ©-estimation sur train uniquement
m_ar_train = smf.ols('log_co2 ~ lag_log_co2', data=train).fit(
    cov_type='HAC', cov_kwds={'maxlags': 3})
m_lin_train = smf.ols('log_co2 ~ lag_log_co2 + log_gdp_c', data=train).fit(
    cov_type='HAC', cov_kwds={'maxlags': 3})
m_quad_train = smf.ols('log_co2 ~ lag_log_co2 + log_gdp_c + I(log_gdp_c**2)', 
    data=train).fit(cov_type='HAC', cov_kwds={'maxlags': 3})
m_cub_train = smf.ols('log_co2 ~ lag_log_co2 + log_gdp_c + I(log_gdp_c**2) + I(log_gdp_c**3)', 
    data=train).fit(cov_type='HAC', cov_kwds={'maxlags': 3})
```

### Comparaison avec benchmarks

```{python}
#| label: benchmarks-calcul
#| output: false

from sklearn.metrics import mean_squared_error, mean_absolute_error
from statsmodels.tsa.arima.model import ARIMA

y_test = test['log_co2']

# 1. ARDL (4 versions)
y_pred_ar = m_ar_train.predict(test)
y_pred_lin = m_lin_train.predict(test)
y_pred_quad = m_quad_train.predict(test)
y_pred_cub = m_cub_train.predict(test)

# 2. Benchmarks naÃ¯fs
y_pred_rw = test['lag_log_co2']  # Marche alÃ©atoire
y_pred_ma = df_usa['log_co2'].rolling(3).mean().shift(1).loc[test.index]

# 3. ARIMA(1,1,1)
arima_model = ARIMA(train['log_co2'], order=(1,1,1)).fit()
y_pred_arima = arima_model.forecast(steps=len(test))

# Calcul des mÃ©triques
def metriques(nom, y_true, y_pred):
    return {
        'ModÃ¨le': nom,
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'MAE': mean_absolute_error(y_true, y_pred),
        'MAPE': np.mean(np.abs((np.exp(y_true) - np.exp(y_pred)) / np.exp(y_true))) * 100
    }

resultats = [
    metriques('Marche alÃ©atoire', y_test, y_pred_rw),
    metriques('Moyenne mobile', y_test, y_pred_ma),
    metriques('ARIMA(1,1,1)', y_test, y_pred_arima),
    metriques('ARDL â€” AR(1)', y_test, y_pred_ar),
    metriques('ARDL â€” LinÃ©aire', y_test, y_pred_lin),
    metriques('ARDL â€” Quadratique', y_test, y_pred_quad),
    metriques('ARDL â€” Cubique', y_test, y_pred_cub),
]

df_perf = pd.DataFrame(resultats).sort_values('RMSE')
```

```{python}
#| label: tbl-performance-oos
#| tbl-cap: "Performance hors-Ã©chantillon (2016-2020)"

from IPython.display import display, Markdown

# On enveloppe le rÃ©sultat dans Markdown() pour qu'il soit rendu visuellement
display(Markdown(df_perf.to_markdown(index=False, floatfmt=('.0s', '.4f', '.4f', '.2f'))))
```

```{python}
#| label: fig-comparaison-modeles
#| fig-cap: "Comparaison visuelle des prÃ©dictions hors-Ã©chantillon"
#| fig-width: 12
#| fig-height: 5

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Graphique 1 : SÃ©ries temporelles
axes[0].plot(test['year'], np.exp(y_test), 'ko-', linewidth=2, markersize=8, label='ObservÃ©')
axes[0].plot(test['year'], np.exp(y_pred_rw), 's--', alpha=0.6, label='Marche alÃ©atoire')
axes[0].plot(test['year'], np.exp(y_pred_arima), '^--', alpha=0.6, label='ARIMA')
axes[0].plot(test['year'], np.exp(y_pred_quad), 'r-', linewidth=2, label='ARDL Quadratique')
axes[0].set_xlabel("AnnÃ©e")
axes[0].set_ylabel("COâ‚‚ par habitant (tonnes)")
axes[0].set_title("A. PrÃ©dictions vs RÃ©alitÃ© (2016-2020)")
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Graphique 2 : Erreurs par modÃ¨le (boxplot)
erreurs = pd.DataFrame({
    'RW': y_test - y_pred_rw,
    'ARIMA': y_test - y_pred_arima,
    'Quad': y_test - y_pred_quad,
})
erreurs.boxplot(ax=axes[1])
axes[1].axhline(0, color='red', linestyle='--')
axes[1].set_ylabel("Erreur de prÃ©diction (log)")
axes[1].set_title("B. Distribution des erreurs")
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### DÃ©cision de sÃ©lection de modÃ¨le

```{python}
#| echo: false

from IPython.display import display, Markdown

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. RÃ‰CUPÃ‰RATION DES MÃ‰TRIQUES (Assurez-vous que df_perf existe)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# RÃ©cupÃ©ration sÃ©curisÃ©e des RMSE
def get_rmse(model_name):
    try:
        return df_perf[df_perf['ModÃ¨le'] == model_name]['RMSE'].values[0]
    except IndexError:
        return np.nan

rmse_lin = get_rmse('ARDL â€” LinÃ©aire')
rmse_quad = get_rmse('ARDL â€” Quadratique')
rmse_cub = get_rmse('ARDL â€” Cubique')
rmse_rw = get_rmse('Marche alÃ©atoire')

# Calculs relatifs
ecart_quad_pct = (rmse_quad - rmse_lin) / rmse_lin * 100
gain_vs_rw = (rmse_rw - min(rmse_lin, rmse_quad)) / rmse_rw * 100

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. ANALYSE DE LA SIGNIFICATIVITÃ‰ (DYNAMIQUE)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# RÃ©cupÃ©ration p-values
try:
    pval_b2 = m_ardl_quad.pvalues.get('I(log_gdp_c ** 2)', m_ardl_quad.pvalues.get('I(log_gdp_c**2)', 1.0))
    pval_b3 = m_ardl_cub.pvalues.get('I(log_gdp_c ** 3)', m_ardl_cub.pvalues.get('I(log_gdp_c**3)', 1.0))
except NameError:
    pval_b2, pval_b3 = 1.0, 1.0

# DÃ©termination du statut statistique
is_quad_sig = pval_b2 < 0.10  # Seuil Ã  10%
is_cub_sig = pval_b3 < 0.10

txt_sig_b2 = "**Significatif**" if is_quad_sig else "Non significatif"
txt_sig_b3 = "**Significatif**" if is_cub_sig else "Non significatif"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. LOGIQUE DE DÃ‰CISION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Choix du modÃ¨le : Si Quadratique n'est pas significatif, on devrait thÃ©oriquement prendre le LinÃ©aire
# MAIS si vous voulez forcer le Quadratique pour cohÃ©rence thÃ©orique, on adapte la justification.

if is_quad_sig:
    modele_retenu = "ARDL Quadratique"
    justification_b2 = f"Le coefficient $\\beta_2$ est significatif (p={pval_b2:.3f}), validant l'hypothÃ¨se de la courbe en U inversÃ© (EKC)."
    tradeoff_txt = "La lÃ©gÃ¨re perte de RMSE est justifiÃ©e par la meilleure spÃ©cification thÃ©orique."
else:
    modele_retenu = "ARDL LinÃ©aire (Statistique) / Quadratique (ThÃ©orique)"
    justification_b2 = f"Le coefficient $\\beta_2$ n'est pas statistiquement significatif (p={pval_b2:.3f}), suggÃ©rant que sur cette pÃ©riode (1990-2020), la relation est principalement linÃ©aire (phase descendante de l'EKC dÃ©jÃ  entamÃ©e)."
    tradeoff_txt = "Le modÃ¨le linÃ©aire est plus performant et plus parcimonieux. Toutefois, nous conservons le modÃ¨le quadratique pour l'analyse structurelle (turning point) par cohÃ©rence avec l'analyse transversale."

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. GÃ‰NÃ‰RATION DU RAPPORT MARKDOWN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

display(Markdown(f"""

**RÃ©sultats de la validation hors-Ã©chantillon :**

1. **Meilleur modÃ¨le global** : {df_perf.iloc[0]['ModÃ¨le']} (RMSE = {df_perf.iloc[0]['RMSE']:.4f})
2. **Gain vs benchmark naÃ¯f** : {gain_vs_rw:+.1f}%

**Comparaison dÃ©taillÃ©e des spÃ©cifications :**

| CritÃ¨re | ARDL LinÃ©aire | ARDL Quadratique | ARDL Cubique |
|:--------|:--------------|:-----------------|:-------------|
| **RMSE (Test)** | **{rmse_lin:.4f}** | {rmse_quad:.4f} ({ecart_quad_pct:+.1f}%) | {rmse_cub:.4f} |
| **Coefficient clÃ©** | â€” | $\\beta_2$ : p={pval_b2:.3f} | $\\beta_3$ : p={pval_b3:.3f} |
| **Statut** | â€” | {txt_sig_b2} | {txt_sig_b3} |
| **AIC** | **{m_ardl_lin.aic:.1f}** | {m_ardl_quad.aic:.1f} | {m_ardl_cub.aic:.1f} |

**MODÃˆLE RETENU : {modele_retenu}**

**Justification de la dÃ©cision :**

1.  **Performance** : Le modÃ¨le LinÃ©aire offre la meilleure performance prÃ©dictive (RMSE le plus bas) et la meilleure parcimonie (AIC le plus bas).
    
2.  **Test de l'EKC ($\\{"beta"}_2$)** : {justification_b2}

3.  **Test du Rebond ($\\{"beta"}_3$)** : Le terme cubique est rejetÃ© (p={pval_b3:.3f}), Ã©cartant l'hypothÃ¨se d'une courbe en N Ã  ce stade.

**Conclusion mÃ©thodologique** : 
{tradeoff_txt}
"""))
```

## Diagnostics du modÃ¨le retenu {#sec-diagnostics-usa}

```{python}
#| label: diagnostics-modele-final
#| fig-cap: "Diagnostics du modÃ¨le ARDL quadratique"
#| fig-width: 12
#| fig-height: 8

# Utiliser le modÃ¨le estimÃ© sur donnÃ©es complÃ¨tes
m_final = m_ardl_quad

fig, axes = plt.subplots(2, 2, figsize=(12, 8))

# 1. RÃ©sidus vs temps
axes[0,0].plot(df_usa['year'], m_final.resid, 'o-')
axes[0,0].axhline(0, color='red', linestyle='--')
axes[0,0].set_xlabel("AnnÃ©e")
axes[0,0].set_ylabel("RÃ©sidus")
axes[0,0].set_title("A. RÃ©sidus temporels")
axes[0,0].grid(True, alpha=0.3)

# 2. RÃ©sidus vs fitted
axes[0,1].scatter(m_final.fittedvalues, m_final.resid)
axes[0,1].axhline(0, color='red', linestyle='--')
axes[0,1].set_xlabel("Valeurs ajustÃ©es")
axes[0,1].set_ylabel("RÃ©sidus")
axes[0,1].set_title("B. RÃ©sidus vs PrÃ©dictions")
axes[0,1].grid(True, alpha=0.3)

# 3. QQ-plot (normalitÃ©)
from scipy import stats
stats.probplot(m_final.resid, dist="norm", plot=axes[1,0])
axes[1,0].set_title("C. Q-Q Plot (Test de normalitÃ©)")

# 4. ACF des rÃ©sidus (autocorrÃ©lation)
from statsmodels.graphics.tsaplots import plot_acf
plot_acf(m_final.resid, lags=10, ax=axes[1,1])
axes[1,1].set_title("D. AutocorrÃ©lation des rÃ©sidus")

plt.tight_layout()
plt.show()
```

```{python}
#| echo: false
from statsmodels.stats.stattools import jarque_bera, durbin_watson
from IPython.display import display, Markdown

# 1. Calcul des statistiques
jb_stat, jb_pval, _, _ = jarque_bera(m_final.resid)
dw_stat = durbin_watson(m_final.resid)

# 2. PrÃ©paration des messages de verdict (pour Ã©viter les backslashes dans la f-string)
jb_verdict = "RÃ©sidus normaux" if jb_pval > 0.05 else "Non-normalitÃ© dÃ©tectÃ©e"
dw_verdict = "Pas d'autocorrÃ©lation" if 1.5 < dw_stat < 2.5 else "AutocorrÃ©lation rÃ©siduelle"

# 3. Affichage
display(Markdown(f"""
**Tests de spÃ©cification** :

| Test | Statistique | p-value | Verdict |
|------|-------------|---------|---------|
| **Jarque-Bera** (normalitÃ©) | {jb_stat:.2f} | {jb_pval:.3f} | {jb_verdict} |
| **Durbin-Watson** (autocorrÃ©lation) | {dw_stat:.2f} | â€” | {dw_verdict} |

**Conclusion des diagnostics** : Le modÃ¨le ARDL quadratique satisfait les hypothÃ¨ses de base 
de la rÃ©gression linÃ©aire. Les rÃ©sidus ne montrent pas de pattern systÃ©matique exploitable.
"""))
```

## InterprÃ©tation Ã©conomique {#sec-interpretation-usa}

### Inertie et demi-vie

```{python}
#| echo: false

rho = m_final.params['lag_log_co2']

if 0 < rho < 0.99:
    halflife = -np.log(0.5) / np.log(rho)
    display(Markdown(f"""
**Coefficient d'inertie** : $\\rho = {rho:.3f}$ | **Demi-vie** : ${halflife:.1f}$ ans

Le coefficient $\\rho$ mesure la persistance des Ã©missions. Une demi-vie de ${halflife:.1f}$ ans 
signifie qu'il faut **${int(halflife*2)}+$ ans** pour qu'une politique climatique ait un effet 
structurel durable (bien au-delÃ  d'un mandat de 4-5 ans).
"""))

elif rho >= 0.99:
    display(Markdown(f"""
**Coefficient d'inertie** : $\\rho = {rho:.3f}$ (proche de la racine unitaire)

Persistance extrÃªme des Ã©missions â†’ Les chocs sont quasi-permanents. Avec seulement 30 observations, 
l'estimateur est biaisÃ© vers le haut (biais de Nickell). La vraie valeur est probablement $\\rho \\approx 0.90â€“0.95$.
"""))

else:
    display(Markdown(f"**Coefficient anormal** : $\\rho = {rho:.3f}$ (devrait Ãªtre entre 0 et 1)."))
```

### Ã‰lasticitÃ© de long terme

```{python}
#| echo: false

rho = m_final.params['lag_log_co2']
beta_pib = m_final.params['log_gdp_c']
beta_pib2 = m_final.params['I(log_gdp_c ** 2)']

log_gdp_moyen = df_usa['log_gdp'].mean()
log_gdp_moyen_c = 0
gdp_moyen_niveau = int(np.exp(log_gdp_moyen))

elasticite_CT = beta_pib + 2 * beta_pib2 * log_gdp_moyen_c

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test de validitÃ© : Ï < 0.99 ?
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if rho >= 0.99:
    # CAS 1 : Ã‰lasticitÃ© LT non calculable
    effet_CT_pct = abs(elasticite_CT)
    verbe_CT = "rÃ©duit" if elasticite_CT < 0 else "augmente"
    
    display(Markdown(f"""
**PIB moyen amÃ©ricain** : ${gdp_moyen_niveau:,}$ \$/hab (PPA 2017)

**Ã‰lasticitÃ© de long terme non calculable** ($\\rho = {rho:.3f} \\approx 1$)

Avec $\\rho \\geq 1$, la formule d'Ã©lasticitÃ© de long terme $\\varepsilon_{{LT}} = \\frac{{\\beta_{{\\text{{PIB}}}}}}{{1 - \\rho}}$ diverge mathÃ©matiquement. Causes possibles : 
petit Ã©chantillon ($n=30$), cointÃ©gration, ou instabilitÃ© structurelle post-2010.

**Ã‰lasticitÃ© de court terme uniquement** : $\\varepsilon_{{CT}} = {elasticite_CT:.3f}$  
â†’ +1\\% PIB **{verbe_CT}** les Ã©missions de **{effet_CT_pct:.2f}\\%** (annÃ©e 1).

**Conclusion** : La relation PIB-CO$_2$ est complexe et potentiellement non-stationnaire. 
Une analyse en panel multi-pays serait nÃ©cessaire pour caractÃ©riser le dÃ©couplage de long terme.
"""))

else:
    # CAS 2 : Calcul valide
    elasticite_LT = elasticite_CT / (1 - rho)
    
    effet_CT_pct = abs(elasticite_CT) * 100
    effet_LT_pct = abs(elasticite_LT) * 100
    verbe_CT = "rÃ©duit" if elasticite_CT < 0 else "augmente"
    verbe_LT = "rÃ©duction" if elasticite_LT < 0 else "augmentation"
    
    halflife_approx = int(-np.log(0.5) / np.log(rho)) if 'HALFLIFE' not in locals() else int(HALFLIFE)
    annees_LT = halflife_approx * 2
    
    display(Markdown(f"""
**PIB moyen amÃ©ricain** : ${gdp_moyen_niveau:,}$ \$/hab (PPA 2017)

| Horizon | Ã‰lasticitÃ© | InterprÃ©tation |
|---------|-----------|----------------|
| **Court terme** (annÃ©e 1) | $\\varepsilon_{{CT}} = {elasticite_CT:.3f}$ | +1\\% PIB **{verbe_CT}** les Ã©missions de **{effet_CT_pct:.2f}\\%** |
| **Long terme** (~{annees_LT} ans) | $\\varepsilon_{{LT}} = {elasticite_LT:.3f}$ | Effet cumulÃ© : **{verbe_LT} de {effet_LT_pct:.2f}\\%** |

**Verdict** : {
    f"**DÃ©couplage confirmÃ©** (Ã©lasticitÃ© nÃ©gative), mais rythme insuffisant pour Net Zero 2050." 
    if elasticite_LT < 0 
    else f"**Couplage persistant** â€” le dÃ©couplage observÃ© en transversal n'est pas encore structurel dans le temps."
}
"""))
```

### Turning point

```{python}
#| echo: false

beta_pib = m_final.params['log_gdp_c']
beta_pib2 = m_final.params['I(log_gdp_c ** 2)']

if rho >= 0.99:
    display(Markdown("""
**Turning point : Non calculable** ($\\rho \\approx 1$ â†’ pas d'Ã©quilibre de long terme dÃ©fini)

**Observation empirique** : Pic ~2005-2007 (~20 t/hab), baisse de 30\\% depuis. 
Mais stabilitÃ© structurelle incertaine (conjoncturel ou durable ?).
"""))

elif beta_pib2 < 0:
    log_pib_turning_c = -beta_pib / (2 * beta_pib2)  # Turning point CENTRÃ‰
    log_pib_turning = log_pib_turning_c + GDP_MEAN_USA  # DÃ©-centrage
    pib_turning = np.exp(log_pib_turning)
    
    if 1000 < pib_turning < 200000:
        pib_usa_actuel = df_usa.iloc[-1]['gdp_pc']
        distance_pct = (pib_usa_actuel - pib_turning) / pib_turning * 100
        
        display(Markdown(f"""
**Turning point** : ${int(pib_turning):,}$ \$/hab | **PIB USA 2020** : ${int(pib_usa_actuel):,}$ \$/hab  
â†’ {"**DÃ©passÃ©**" if pib_usa_actuel > pib_turning else "**Pas atteint**"} (${distance_pct:+.1f}$\\%)

{
    f"Les USA sont en **phase descendante** de l'EKC. Mais ce dÃ©couplage reste trop lent pour Paris 2030." 
    if pib_usa_actuel > pib_turning 
    else "Contradiction avec les donnÃ©es (baisse depuis 2005) â†’ le modÃ¨le lisse les ruptures post-2010."
}
"""))
    else:
        display(Markdown(f"""
**Turning point incohÃ©rent** (${int(pib_turning):,}$ \$/hab, hors plage rÃ©aliste 10kâ€“100k).  
**Observation empirique** : Pic ~2005-2007 (~45kâ€“50k \$/hab).
"""))

else:
    display(Markdown(f"""
**Pas de turning point** ($\\beta_2 = {beta_pib2:.4f} \\geq 0$, pas de U inversÃ©).  
Contradiction avec donnÃ©es observÃ©es â†’ le dÃ©couplage post-2010 est trop rÃ©cent pour ce modÃ¨le global.
"""))
```


## Projection 2021-2025 {#sec-projection-usa}

```{python}
#| label: projection-avec-ic
#| output: false

# MÃªme logique que l'actuel, mais avec get_prediction() pour les IC

last_obs = df_usa.iloc[-1]
future_years = list(range(ANNEE_FIN + 1, ANNEE_FIN + 6))

future_df = []
curr_log_co2 = last_obs['log_co2']
curr_log_gdp = last_obs['log_gdp']

TAUX_CROISSANCE_ANNUEL = 0.02

for year in future_years:
    curr_log_gdp += np.log(1 + TAUX_CROISSANCE_ANNUEL) 
    curr_log_gdp_c = curr_log_gdp - GDP_MEAN_USA
    
    X_fut = pd.DataFrame({
        'lag_log_co2': [curr_log_co2],
        'log_gdp_c': [curr_log_gdp_c]
    })
    X_fut['I(log_gdp_c ** 2)'] = X_fut['log_gdp_c'] ** 2
    
    # PrÃ©diction avec intervalle
    pred = m_final.get_prediction(X_fut)
    pred_summary = pred.summary_frame(alpha=0.05)
    
    future_df.append({
        'year': year,
        'log_co2_pred': pred_summary['mean'].values[0],
        'log_co2_lower': pred_summary['mean_ci_lower'].values[0],
        'log_co2_upper': pred_summary['mean_ci_upper'].values[0],
    })
    
    curr_log_co2 = pred_summary['mean'].values[0]

df_future = pd.DataFrame(future_df)
df_future['co2_pred'] = np.exp(df_future['log_co2_pred'])
df_future['co2_lower'] = np.exp(df_future['log_co2_lower'])
df_future['co2_upper'] = np.exp(df_future['log_co2_upper'])
```

```{python}
#| label: fig-projection-ic
#| fig-cap: "Projection USA 2021-2025 avec intervalles de confiance 95%"

fig, ax = plt.subplots(figsize=(12, 6))

# Historique
ax.plot(df_usa['year'], df_usa['co2_per_capita'], 
        'ko-', linewidth=2, markersize=6, label='Historique')

# Projection
ax.plot(df_future['year'], df_future['co2_pred'], 
        'r--', linewidth=2.5, marker='s', markersize=8, label='Projection (+2% PIB/an)')

# Intervalle de confiance
ax.fill_between(df_future['year'], 
                df_future['co2_lower'], 
                df_future['co2_upper'],
                color='red', alpha=0.2, label='IC 95%')

ax.axvline(ANNEE_FIN, color='gray', linestyle=':', linewidth=2)
ax.text(ANNEE_FIN + 0.3, ax.get_ylim()[1]*0.95, 
        'Limite\nhistorique', fontsize=9, va='top')

ax.set_xlabel("AnnÃ©e", fontsize=12)
ax.set_ylabel("COâ‚‚ par habitant (tonnes)", fontsize=12)
ax.set_title("Projection USA : ScÃ©nario tendanciel (+2% PIB/an)", fontsize=14, fontweight='bold')
ax.legend(fontsize=10)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

```{python}
#| echo: false

CO2_2020 = df_usa.iloc[-1]['co2_per_capita']
CO2_2025 = df_future.iloc[-1]['co2_pred']
variation = (CO2_2025 - CO2_2020) / CO2_2020 * 100

display(Markdown(f"""
**Tableau de projection** :

| AnnÃ©e | COâ‚‚ prÃ©dit | IC 95% | Variation cumulÃ©e |
|:-----:|:----------:|:------:|:-----------------:|
""" + "\n".join([
    f"| {row['year']} | {row['co2_pred']:.2f} | [{row['co2_lower']:.2f} ; {row['co2_upper']:.2f}] | {(row['co2_pred'] - CO2_2020)/CO2_2020*100:+.1f}% |"
    for _, row in df_future.iterrows()
]) + f"""

**Message clÃ©** : Sous l'hypothÃ¨se de croissance tendancielle (+2%/an), les Ã©missions 
amÃ©ricaines {
    f"**baisseraient de {abs(variation):.1f}%**" if variation < 0 
    else f"**augmenteraient de {variation:.1f}%**"
} d'ici 2025.

**Limites de cette projection** :

1. **Incertitude croissante** : L'intervalle de confiance s'Ã©largit (Â±{(df_future.iloc[-1]['co2_upper'] - df_future.iloc[-1]['co2_lower'])/2:.1f} t en 2025)
2. **HypothÃ¨se de stabilitÃ© structurelle** : Suppose que la relation PIB-COâ‚‚ estimÃ©e sur 1990-2020 reste valide
3. **Pas de chocs exogÃ¨nes** : Ignore les politiques climatiques futures, crises, ruptures technologiques
4. **ScÃ©nario unique** : Un scÃ©nario bas-carbone (+1% PIB, forte dÃ©carbonation) donnerait des rÃ©sultats trÃ¨s diffÃ©rents

**â†’ Ces projections sont des **extrapolations conditionnelles**, pas des prÃ©visions certaines.**
"""))
```

## RÃ©sumÃ© de l'analyse temporelle

```{python}
#| echo: false

# 1. Calculs intermÃ©diaires pour simplifier l'affichage final

# ElasticitÃ©
if 'elasticite_LT' in locals() and not np.isnan(elasticite_LT):
    texte_elasticite = f"{elasticite_LT:+.3f}"
    interp_elasticite = "Couplage persistant" if elasticite_LT > 0 else "DÃ©couplage confirmÃ© structurellement"
else:
    texte_elasticite = "Non calculable ($\\rho \\approx 1$)"
    interp_elasticite = "Relation complexe/non-stationnaire"

# Halflife / Inertie
if 'HALFLIFE' in locals() and not np.isnan(HALFLIFE):
    texte_halflife = f"{HALFLIFE:.1f} ans"
    texte_inertie = f"Le dÃ©couplage est **lent** : une politique doit Ãªtre maintenue $> {int(HALFLIFE*2)}$ ans"
else:
    texte_halflife = "Non calculable ($\\rho \\approx 1$)"
    texte_inertie = "Persistance extrÃªme (processus quasi non-stationnaire)"

# InterprÃ©tation Projection 2025 (Sortie de la f-string pour lisibilitÃ©)
if variation < 0 and variation > -20:
    interp_2025 = "Baisse modeste, insuffisante pour Net Zero 2050"
elif variation > 0:
    interp_2025 = "Hausse inquiÃ©tante, incompatible avec Paris"
else:
    interp_2025 = "Baisse significative, compatible avec transition"

# Conclusion finale (C'est ici que l'erreur se produisait)
# On dÃ©finit le texte contenant du LaTeX AVANT de l'insÃ©rer
if 'elasticite_LT' in locals() and elasticite_LT < 0:
    conclusion_finale = "le dÃ©couplage reste **trop lent**"
else:
    # Notez les doubles backslashes pour que Python comprenne qu'il s'agit d'un caractÃ¨re LaTeX
    # Mais ici on utilise des accolades simples {} car nous ne sommes plus dans une f-string
    conclusion_finale = "la relation PIB-$\\text{CO}_2$ est complexe et instable"

# 2. Affichage
display(Markdown(f"""
**RÃ©sultats clÃ©s** :

1. **ModÃ¨le retenu** : ARDL Quadratique  
   â†’ Terme cubique non significatif ($p = {m_ardl_cub.pvalues['I(log_gdp_c ** 3)']:.3f}$) 
   â†’ Courbe en N **non dÃ©tectÃ©e** sur 1990-2020

2. **Inertie structurelle** : $\\rho = {rho:.3f}$, demi-vie = {texte_halflife}  
   â†’ {texte_inertie}

3. **Ã‰lasticitÃ© long terme** : {texte_elasticite}  
   â†’ {interp_elasticite}

4. **Projection 2025** : {CO2_2025:.1f} $\\text{{tCO}}_2/\\text{{hab}}$ ({variation:+.1f}% vs 2020)  
   â†’ {interp_2025}

**â†’ La trajectoire amÃ©ricaine ne montre PAS de rebond (courbe en N), mais {conclusion_finale} 
pour atteindre les objectifs climatiques sans rupture politique majeure.**
"""))
```
