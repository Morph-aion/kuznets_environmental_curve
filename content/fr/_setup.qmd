```{python}
#| label: setup
#| output: false
#| cache: false

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.tsa.stattools import adfuller
from statsmodels.stats.diagnostic import het_breuschpagan, acorr_ljungbox
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.stattools import durbin_watson
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
from scipy import stats
from IPython.display import Markdown, display

# Configuration graphique
sns.set_theme(style="whitegrid", context="paper", palette="colorblind")
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 11


# ═══════════════════════════════════════════════════════════════════
# DÉTECTION AUTOMATIQUE DU CHEMIN (fonctionne depuis content/ ET presentation/)
# ═══════════════════════════════════════════════════════════════════

def find_data_file():
    """Cherche le fichier de données en remontant l'arborescence"""
    from pathlib import Path
    
    current = Path.cwd()
    
    # Liste des chemins possibles (ordre de probabilité)
    possible_paths = [
        current / "data/01_raw/kuznets_data_final.csv",              # Depuis racine
        current.parent / "data/01_raw/kuznets_data_final.csv",       # 1 niveau
        current.parent.parent / "data/01_raw/kuznets_data_final.csv" # 2 niveaux (content/fr ou presentation/fr)
    ]
    
    for path in possible_paths:
        if path.exists():
            return path
    
    raise FileNotFoundError(
        f"❌ Impossible de trouver kuznets_data_final.csv.\n"
        f"Chemins testés :\n" + 
        "\n".join([f"  - {p}" for p in possible_paths])
    )

# ═══════════════════════════════════════════════════════════════════
# CHARGEMENT ET PRÉPARATION DES DONNÉES
# ═══════════════════════════════════════════════════════════════════

DATA_LOADED = False

#try:
#    df = pd.read_csv("../../data/01_raw/kuznets_data_final.csv")
#    DATA_LOADED = True

try:
    data_path = find_data_file()
    print(f"✅ Données chargées depuis : {data_path}")
    
    df = pd.read_csv(data_path)
    DATA_LOADED = True
    
    # ─────────────────────────────────────────────────────────────────
    # DONNÉES TRANSVERSALES
    # ─────────────────────────────────────────────────────────────────
    
    ANNEE_CROSS = int(df['year'].max())
    df_cross = df[df['year'] == ANNEE_CROSS].copy()
    
    # Exclusions (micro-États et paradis fiscaux)
    # Justification : Micro-États (<500k hab) et paradis fiscaux 
    # ont une structure économique atypique (PIB/hab artificiellement gonflé)
    EXCLUSIONS = [
        'Liechtenstein', 'Monaco', 'San Marino', 'Andorra',  # Micro-États
        'Luxembourg', 'Ireland', 'Singapore', 'Malta', 'Cyprus',  # Hubs financiers
        'Palau', 'Nauru', 'Tuvalu', 'Vatican'  # Micro-États insulaires
    ]
    
    # Nettoyage    
    df_cross = df_cross[~df_cross['country'].isin(EXCLUSIONS)]
    df_cross = df_cross.dropna(subset=['gdp_per_capita', 'co2_per_capita'])
    
    # Transformations log
    df_cross['log_gdp'] = np.log(df_cross['gdp_per_capita'])
    df_cross['log_co2'] = np.log(df_cross['co2_per_capita'])

    # Création d'un alias pratique pour l'affichage plus tard
    # (S'assure qu'on utilise bien la colonne divisée par la population)    
    df_cross['gdp_pc'] = df_cross['gdp_per_capita']
    
    # Centrage pour réduire multicolinéarité polynomiale
    GDP_MEAN = df_cross['log_gdp'].mean()
    df_cross['log_gdp_c'] = df_cross['log_gdp'] - GDP_MEAN
    
    N_PAYS_EXCLUS = len(EXCLUSIONS)
    N_PAYS = len(df_cross)
    
    # ─────────────────────────────────────────────────────────────────
    # DONNÉES TEMPORELLES (USA)
    # ─────────────────────────────────────────────────────────────────
    
    df_usa = df[df['country'] == 'United States'].sort_values('year').copy()
    
    if not df_usa.empty:
        # Donnée brute disponible dès 1990
        ANNEE_DEBUT_DATA = int(df_usa['year'].min())  # 1990

        # Transformations log      
        df_usa['log_co2'] = np.log(df_usa['co2_per_capita'])
        df_usa['log_gdp'] = np.log(df_usa['gdp_per_capita'])
        
        # Création d'un alias pratique pour l'affichage plus tard
        df_usa['gdp_pc'] = df_usa['gdp_per_capita']

        # Centrage USA, Moyenne calculée AVANT dropna pour cohérence
        GDP_MEAN_USA = df_usa['log_gdp'].mean()
        df_usa['log_gdp_c'] = df_usa['log_gdp'] - GDP_MEAN_USA

        # Création des lags (APRÈS centrage)
        df_usa['lag_log_co2'] = df_usa['log_co2'].shift(1)
        df_usa['lag_log_gdp_c'] = df_usa['log_gdp_c'].shift(1) 
        
        # Nettoyage : enlève la première observation (1990) car lag = NaN
        df_usa = df_usa.dropna()

        # Estimation démarre en 1991 (après création du lag)
        ANNEE_DEBUT_ESTIM = int(df_usa['year'].min())  # 1991
        ANNEE_FIN = int(df_usa['year'].max())          # 2020
        N_OBS_USA = len(df_usa)                        # 30 observations
    else:
        N_OBS_USA = ANNEE_DEBUT = ANNEE_FIN = 0

except FileNotFoundError:
    print("⚠️ ERREUR : Fichier data/01_raw/kuznets_data_final.csv introuvable.")
    print("   Vérifiez le chemin relatif depuis le répertoire du notebook.")
    df_cross = pd.DataFrame()
    df_usa = pd.DataFrame()
    N_PAYS = N_PAYS_EXCLUS = N_OBS_USA = 0
    ANNEE_DEBUT_DATA = ANNEE_DEBUT_ESTIM = ANNEE_FIN = ANNEE_CROSS = 0
    GDP_MEAN = GDP_MEAN_USA = 0

except ValueError as e:
    print(f"⚠️ ERREUR DE DONNÉES : {e}")
    print("   Causes possibles : valeurs négatives dans PIB ou CO₂, types incorrects.")
    df_cross = pd.DataFrame()
    df_usa = pd.DataFrame()
    N_PAYS = N_PAYS_EXCLUS = N_OBS_USA = 0
    ANNEE_DEBUT_DATA = ANNEE_DEBUT_ESTIM = ANNEE_FIN = ANNEE_CROSS = 0
    GDP_MEAN = GDP_MEAN_USA = 0

except Exception as e:
    print(f"⚠️ ERREUR INATTENDUE : {e}")
    import traceback
    traceback.print_exc()
    df_cross = pd.DataFrame()
    df_usa = pd.DataFrame()
    N_PAYS = N_PAYS_EXCLUS = N_OBS_USA = 0
    ANNEE_DEBUT_DATA = ANNEE_DEBUT_ESTIM = ANNEE_FIN = ANNEE_CROSS = 0
    GDP_MEAN = GDP_MEAN_USA = 0
```
