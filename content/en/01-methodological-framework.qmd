---
title: "Methodology"
---

{{< include _footnotes.qmd >}}

## Our three key choices

### Territorial emissions: an accepted limitation

A country can "decarbonize" by relocating its polluting production. This *pollution haven* bias[^haven] distorts EKC tests based on territorial emissions.

| Indicator | What it measures | Limitation |
|-----------|------------------|------------|
| **Territorial emissions** | Locally produced CO$_2$ | Ignores imports ("decoupling illusion") |
| Carbon footprint | CO$_2$ consumed (prod. + imports - exports) | Neutralizes relocation |

**Example**: Europe has reduced its territorial emissions by 20% since 1990, but its carbon footprint by only 5% (Peters et al., 2011).

### Testing the functional form (quadratic vs. cubic)

Classical literature often imposes an inverted U-shape (quadratic model). However, this approach is restrictive: it mathematically rules out the possibility of a new rebound in emissions at very high income levels (N-curve theory).

To avoid masking this potential phenomenon, we estimate a third-degree polynomial model:

$$\ln(CO_2)_i = \beta_0 + \beta_1 \ln(GDP)_i + \beta_2 [\ln(GDP)_i]^2 + \beta_3 [\ln(GDP)_i]^3 + \varepsilon_i$$

**Validation of the log-log form**: A Box-Cox test (see @sec-box-cox) 
confirms that the logarithmic transformation is empirically justified 
($\lambda_{\text{optimal}} = 0.15$, close to 0). This specification 
allows the coefficients to be interpreted as elasticities.

**Interpretation** (under the assumption $\beta_1 > 0$, $\beta_2 < 0$):

- If $\beta_3 = 0$ (not significant): Inverse U of the classic EKC (the quadratic model was sufficient).
- If $\beta_3 < 0$ (significant): Accelerated decline (Decoupling increases with wealth).
- If $\beta_3 > 0$ (significant): N-shaped curve (Worrying rebound: wealth ends up polluting again).

*Note: The interpretation assumes $\beta_1 > 0$ and $\beta_2 < 0$, conditions verified in our estimates (Table 4.1).*

### Note on omitted variables

**Methodological disclaimer**: The models estimated in this report 
(sections 4 and 5) are **parsimonious specifications** that include 
only GDP as an explanatory variable.

We do not control for:
- Sectoral structure (share of industry)
- Energy mix composition (renewables vs. fossil fuels)
- Population density
- Institutional quality

**Implication**: If these factors are correlated with GDP, our coefficients 
may suffer from **omitted variable bias**. The results should 
be interpreted as conditional associations, not causal effects 
"all other things being equal."

This limitation is discussed in detail in the section on methodological limitations 
(to be included in a future extension of the work).

## Estimators

- **Cross-sectional**: OLS[^ols] with **HC3** robust standard errors[^hc3]
- **Temporal**: ARDL[^ardl] with **Newey-West** standard errors[^nw] (3 lags)

**Full technical justification**: @sec-estimators-corrections

::: {.callout-note collapse="true"}
### Technical details

**OLS estimator**:
$$\hat{\beta} = (X'X)^{-1}X'Y$$

**Robust variance HC3**:
$$\widehat{\text{Var}}_{HC3}(\hat{\beta}) = (X'X)^{-1} \left( \sum_{i=1}^n \frac{\hat{\varepsilon}_i^2}{(1-h_{ii})^2} x_i x_i' \right) (X'X)^{-1}$$

**Newey-West variance** (L=3):
$$\widehat{\text{Var}}_{NW}(\hat{\beta}) = (X'X)^{-1} \hat{\Omega} (X'X)^{-1}$$

where $\hat{\Omega} = \hat{\Gamma}_0 + \sum_{j=1}^3 \left(1 - \frac{j}{4}\right) (\hat{\Gamma}_j + \hat{\Gamma}_j')$
:::

## Prediction and validation strategy

### Predictive objectives

Unlike estimation, which seeks to **understand** the GDP-CO$_2$ relationship,
prediction aims to **anticipate** future emissions conditional 
on growth scenarios.

**Concrete applications**:

- Net Zero 2050 projections
- NDC assessment
- National carbon budgets

### Validation protocols

#### Cross-validation: k-fold cross-validation

- **Principle**: Divide the 159 countries into 5 balanced groups
- **Procedure**: Estimate on 4/5, predict on 1/5, repeat 5 times
- **Metric**: Average RMSE (penalizes large errors)

**Why k=5?** Standard bias-variance trade-off (Hastie et al., 2009).
k=10 would result in training sets that are too small (n=143).

#### Time series analysis: expanding window

- **Principle**: Expanding estimation window that respects chronology
- **Example**: Estimate 1990-2010 → predict 2011; then 1990-2011 → predict 2012, etc.
- **Advantage**: Simulates a real-time forecaster (no data leakage)

### Performance metrics

| Metric | Formula | Interpretation |
|--------|---------|----------------|
| **RMSE** | $\sqrt{\frac{1}{n}\sum (y_i - \hat{y}_i)^2}$ | Quadratic error (penalizes outliers) |
| **MAE** | $\frac{1}{n}\sum |y_i - \hat{y}_i|$ | Absolute error (robust to outliers) |
| **MAPE** | $\frac{100}{n}\sum \left|\frac{y_i - \hat{y}_i}{y_i}\right|$ | Relative error (%) |

**Why RMSE?** Consistent with OLS (minimizes SSR).

### Benchmarks

A model is only "good" relative to alternatives. We systematically compare 
to:

- **Random walk**: $\hat{y}_{t+1} = y_t$ (naive benchmark)
- **Moving average**: $\hat{y}_{t+1} = \frac{1}{3}(y_t + y_{t-1} + y_{t-2})$
- **ARIMA(1,1,1)**[^arima]: Optimized univariate model (without GDP)

**If our cubic ARDL model does not beat the random walk, it is useless.**
